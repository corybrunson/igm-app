\documentclass{article}

\begin{document}

This scatterplot compares the extent of consensus among the panelists on a question to the extent of clear opinion on that question.

For each panelist \(i=1,\ldots,N\) and each question \(j=1,\ldots,M\), encode \(i\)'s response to \(j\) as agreement (\(r_{ij}=+1\)), disagreement (\(r_{ij}=-1\)), or uncertainty (\(r_{ij}=0\)). (These calculations ignore strong (dis)agreement. \(r_{ij}\) is not defined if \(i\) left no opinion on \(j\).) The panelists also recorded their confidence \(C_{ij}\in[1,9]\) in their answers; we standardize this measure to \(C'_{ij}=C_{ij}/\overline{C}\) and calculate {\em confidence weights} \(c_{ij}=1-\gamma+\gamma C'_{ij}\), where \(\gamma\) is a tuning parameter, controlled by the user, that interpolates between \(c_{ij}\equiv 1\) and \(c_{ij}=C'_{ij}\).

Write \((i,j)\) if panelist \(i\) responded to question \(j\). The {\em uncertainty} of question \(j\) is \(\sum_{(i,j)}{c_{ij}(1-|r_{ij}|)}/\sum_{(i,j)}{c_{ij}}\), the ratio of uncertain responses to all responses. The {\em consensus} of question \(j\) is calculated, analogously to the \(\tau_a\) statistic, as \(\sum_{(i,j),(i',j)}{r_{ij}r_{i'j}}/{comb(\sum_{(i,j)}{|r_{ij}|},2)}\), the (unweighted) ratio of the difference between the numbers of agreements and of disagreements (concordance minus discordance) to the number of pairs of clear responses (\(comb(a,b)=a!/(b!(a-b)!)\)).

\end{document}